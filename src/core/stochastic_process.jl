#  Copyright 2020, Tom Van Acker
################################################################################
# MultiStateSystems.jl
# A Julia package to solve multi-state system models.
# See http://github.com/timmyfaraday/MultiStateSystems.jl
################################################################################

"""
# Stochastic processes
"""
function solve!(std::AbstractSTD, tsim::Number)
    # TODO - update_std_info!(std)
    is_a_markov_process(std) ? solve_markov_process!(std, tsim) : ~ ;
end

"""
## Markov Process

State-space:     discrete
Time-space:      continuous
Renewal process: TRUE
Markov property: TRUE

A Markov process is described by a random variable Xâ‚œ, where t denotes the
calendar time. The possible values of Xâ‚œ is represented by the discrete state-
space ğ“¢ of the process.

A Markov process respects the Markov property, which means it respects
    â„™(Xâ‚œ âˆˆ ğ“¢ | ğ“•â‚›) = â„™(Xâ‚œ âˆˆ ğ“¢ | Xâ‚›), âˆ€ s,t âˆˆ ğ•€: s < t,
where ğ“•â‚› represents a filtration of a probability space (Î©,ğ“•,â„™) and ğ•€ a totally
ordered index set. A Markov process is described by Kolmogorov equations, more
specifically the Kolmogorov forward equations:
    Î´páµ¢â±¼(s;t)/Î´t = âˆ‘â‚– páµ¢â‚–(s;t) â‹… Aâ‚–â±¼(t), âˆ€ i,j âˆˆ ğ“¢, s,t âˆˆ ğ•€: s < t,
where A(t) represents the transition matrix, syn., generator matrix.

The latter describe an initial value problem for finding the state
probabilities, given transition rates Ïáµ¢â±¼(t) and initial values Î´áµ¢:
    dpáµ¢(t)/dt = - âˆ‘â±¼ Ïáµ¢â±¼(t)páµ¢(t) + âˆ‘â±¼ Ïâ±¼áµ¢(t)pâ±¼(t),  âˆ€ i âˆˆ ğ“¢.
"""
const markov_props = [:renewal,:markovian]
is_a_markov_process(std::AbstractSTD) =
    prod(getfield(std.props[:info],prop) for prop in markov_props)

function homogeneous_markov_process(du, u, p, t)
    G, Ï, info = p
    for ns in 1:_LG.nv(G)
        if info[ns].trapping
            du[ns] = sum(Ï[_LG.Edge(nt,ns)]*u[nt]
                            for nt in _LG.inneighbors(G,ns)
                            if ns â‰  nt)
        else
            du[ns] = sum(Ï[_LG.Edge(nt,ns)]*u[nt]
                            for nt in _LG.inneighbors(G,ns)
                            if ns â‰  nt) -
                     sum(Ï[_LG.Edge(ns,nt)]*u[ns]
                            for nt in _LG.outneighbors(G,ns)
                            if ns â‰  nt)
    end end
end
function inhomogeneous_markov_process(du, u, p, t)
    G, Ï, info = p
    for ns in 1:_LG.nv(G)
        if info[ns].trapping
            du[ns] = sum(Ï[_LG.Edge(nt,ns)](t)*u[nt]
                            for nt in _LG.inneighbors(G,ns)
                            if ns â‰  nt)
        else
            du[ns] = sum(Ï[_LG.Edge(nt,ns)](t)*u[nt]
                            for nt in _LG.inneighbors(G,ns)
                            if ns â‰  nt) -
                     sum(Ï[_LG.Edge(ns,nt)](t)*u[ns]
                            for nt in _LG.outneighbors(G,ns)
                            if ns â‰  nt)
    end end
end

function solve_markov_process!(std::STD, tsim::Number; tol::Real = 1e-8)
    p   = [std.graph,get_tprop(std,:rate),get_sprop(std,:info)]
    uâ‚€  = get_sprop(std,:init)
    ts  = (0.0_UF.unit(tsim),tsim)

    if get_info(std,:time_homogeneous)
        prob = _ODE.ODEProblem(homogeneous_markov_process,uâ‚€,ts,p)
    else
        prob = _ODE.ODEProblem(inhomogeneous_markov_process,uâ‚€,ts,p)
    end
    sol = _ODE.solve(prob,_ODE.RK4(),reltol = tol,abstol = tol)

    set_prop!(std,:time,sol.t)
    set_prop!(std,states(std),:prob,[sol[ns,:] for ns in states(std)])

    set_info!(std,:solved,true)
end
